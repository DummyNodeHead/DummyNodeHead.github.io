# 模型评估与选择

## 过拟合与欠拟合

在实际应用中，我们期望我们的模型能够在新样本上表现的很好。所以我们应该控制模型尽可能从训练样本中学出适用于所有潜在样本的规律。但是，我们不能把训练样本学的“太好”。由于训练样本只是总样本空间的一部分，如果过度训练，模型很可能会把这一部分自己的一些特点也当作了所有样本的一般性质学习下来。这种情况就是过拟合。过拟合往往在训练集上有着极高的精度，但在测试集里的错误率却明显上升。

欠拟合与过拟合相反，即模型学习能力太低没有很好地学到一般规律。欠拟合相比过拟合更加容易克服。比如增加训练轮数，加深网络层数等都可以帮助解决欠拟合。但过拟合就更难解决了，而且过拟合是无法彻底避免的，我们能做的只有“缓解”。